getwd(0)
getwd()
source("gettingTheData/gettingData.R")
url <- https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv
"
url()
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(dataUrl, destfile = "./gettingTheData/AmCo.csv", method = "curl")
mydata = read.csv("./gettingTheData/AmCo.csv")
head(mydata,10)
count(mydata$VAL == 22)
sum(mydata$VAL == 22)
sum(mydata$VAL == 24)
sum(mydata$VAL === 24)
sum(mydata$VAL = 24)
sum(mydata$VAL == 24)
sum(mydata$VAL == "24")
length(which(mydata$VAL == 24))
length(which(mydata$VAL == 24))
dataUrlExc <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(dataUrlExc, destfile = "./gettingTheData/NaGasAcq.xlsx", method = "curl")
library(xlsx)
install.packages('xlsx')
library(xlsx)
install.packages('xlsx')
library(xlsx)
install.packages('xlsx2')
myData2 <- read.xlsx("./gettingTheData/NaGasAcq.xlsx", sheetIndex=1,header=TRUE)
sudo R CMD javareconf
install.packages("rJava",type='source')
install.packages("rJava", type = "source")
install.packages('xlsx')
library(xlsx)
library(XLConnect)
install.packages('XLConnect')
library(XLConnect)
library(XLConnect)
library(xlsx)
myData2 <- read.xlsx("./gettingTheData/NaGasAcq.xlsx", sheetIndex=1,header=TRUE)
colInd <- 7:15
rowInd <- 18:23
dat <- read.xlsx("./gettingTheData/NaGasAcq.xlsx", sheetIndex=1,header=TRUE, colIndex = colInd, rowIndex = rowInd)
sum(dat$Zip*dat$Ext,na.rm=T)
xmlLink <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
install.packages('XML')
library(XML)
docXML <- xmlTreeParse(xmlLink, useInternal=TRUE)
xmlLink <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
docXML <- xmlTreeParse(xmlLink, useInternal=TRUE)
download.file(xmlLink, destfile = "./gettingTheData/xmlFile.xml", method = "curl")
docXML <- xmlTreeParse("./gettingTheData/xmlFile.xml", useInternal=TRUE)
head(docXML, 5)
rootNode <- xmlRoot(docXML)
names(rootNode)
rootNode[[1]]
rootNode[[1]][[1]]
install.packages('XPath')
urlCSV <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(urlCSV, destfile = "./gettingTheData/csvFile2.csv", method = "curl")
data <- fread("./gettingTheData/csvFile2.csv")
library("data.table")
library(data.table)
install.packages('data.table')
library(data.table)
data <- fread("./gettingTheData/csvFile2.csv")
source("gettingTheData/gettingData.R")
testTime(data)
DT <- data
testTime(data)
source("gettingTheData/gettingData.R")
testTime(data)
source("gettingTheData/gettingData.R")
testTime(data)
source("gettingTheData/gettingData.R")
testTime(data)
source("gettingTheData/gettingData.R")
testTime(data)
testTime(DT)
source("gettingTheData/gettingData.R")
testTime(DT)
install.packages("RMySQL")
library(RMySQL)
library(RMySQL)
ucsdDB <- dbConnect(MySQL(),user="genome",host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucsdDB, "SHOW DATABASES;"); dbDisconnect(ucsdDB);
result
hg19 <- dbConnect(MySQL(),user="genome", db="hg19", host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:10]
dbListFields(hg19, "affyU133Plus2")
hg19 <- dbConnect(MySQL(),user="genome", db="hg19", host="genome-mysql.cse.ucsc.edu")
dbListFields(hg19, "affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
createdH5 <- h5createFile("example.h5")
createdH5
createdH5 <- h5createGroup("xample.h5, ""foo)
createdH5 <- h5createGroup("example.h5", "foo")
createdH5 <- h5createGroup("example.h5", "baa")
createdH5 <- h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")
A = matrix(1:10, nr=5,nc=2)
h5write("example.h5", "foo/A")
h5write(A,"example.h5", "foo/A")
h5ls("example.h5")
read! <- h5read("example.h5","foo/A")
readA <- h5read("example.h5","foo/A")
readA
h5write(c(12,13,14), "example.h5", "foo/A",index=list(1:3,1))
readA <- h5read("example.h5","foo/A")
readA
install.packages("httr")
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html <- GET(url)
contentHTML <- content(html, as="text")
con = url(url)
htmlCode = readLines(con)
close(con)
htmlCode
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
url2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
read.fwf(url2)
x <- read.fwf(
file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip=4)
x <- read.fwf(
file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip=4, widths=c(12, 7, 4, 9, 4, 9, 4, 9, 4))
x
x["V1"]
head(x[V2],10)
head(x["V2"],10)
sum(x["V4"])
library(dplyr)
library('dplyr')
library(dplyr)
install.packages('dplyr')
library(dplyr)
getwd()
data = read.csv("gettingTheData/AmericanCommunitySurvey.csv", header = TRUE)
head(data,10)
agricultureLogical <- ACR == 3 & AGS == 6
agricultureLogical <- data$ACR == 3 & data$AGS == 6
which(agricultureLogical)
install.packages("jpeg")
library(jpeg)
help(jpeg)
imageFile <- jpeg("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native=TRUE)
imageFile <- jpeg("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
imageFile <- jpeg(https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg)
imageFile <- jpeg(filename = "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
imageFile <- jpeg("gettingTheData/getdataImg.jpg")
imageFile
print(imageFile)
imageFile <- jpeg("gettingTheData/getdataImg.jpg", native=TRUE)
help("readJPEG")
imageFile <- readJPEG("gettingTheData/getdataImg.jpg", native=TRUE)
head(imageFIle,10)
imageFile
data.class(imageFile)
str(imageFile)
quantile(imageFile,probs=c(0.3,0.8))
DataGDP <- read.csv("gettingTheData/GrossProduct.csv", header = TRUE)
DataEducational <- read.csv("gettingTheData/EducationalData.csv", header = TRUE)
head(dataGDP,5)
head(DataGDP,5)
head(DataEducational,5)
mergedData <- merge(DataGDP,DataEducational,by.x="X", by.y="CountryCode")
nrow(mergedData)
mergedData
count(mergedData$X, na.rm=TRUE)
count(mergedData$X)
mergedData$X
mergedData[order(mergedData$X.3),]
mergedData <- mergedData[order(mergedData$X.3),]
mergedData[13,]
sum(!is.na(unique(mergedData$rankingGDP)))
sum(!is.na(unique(mergedData$X.3)))
mergedData[order(Gross.domestic.product.2012, decreasing = TRUE), list(CountryCode, Long.Name.x,
Gross.domestic.product.2012, X.3)][13]
mergedData[order(Gross.domestic.product.2012, decreasing = TRUE), list(X, Long.Name,
Gross.domestic.product.2012, X.3)][13]
mergedData[order(Gross.domestic.product.2012, decreasing = TRUE), list(X, Long.Name, Gross.domestic.product.2012, X.3)][13]
mergedData[order(Gross.domestic.product.2012, decreasing = TRUE), list("X", Long.Name, Gross.domestic.product.2012, X.3)][13]
mergedData[order(Gross.domestic.product.2012, decreasing = TRUE), list("X", "Long.Name", "Gross.domestic.product.2012", "X.3")][13]
mergedData[order(Gross.domestic.product.2012, decreasing = TRUE), ][13]
mergedData[order(mergedData$Gross.domestic.product.2012, decreasing = TRUE), ][13]
mergedData[order(mergedData$Gross.domestic.product.2012, decreasing = TRUE), ][,13]
mergedData[order(mergedData$Gross.domestic.product.2012, decreasing = TRUE), ]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
f <- file.path(getwd(), "GDP.csv")
download.file(url, f)
dtGDP <- data.table(read.csv(f, skip = 4, nrows = 215))
dtGDP <- dtGDP[X != ""]
dtGDP <- dtGDP[, list(X, X.1, X.3, X.4)]
setnames(dtGDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP",
"Long.Name", "gdp"))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
f <- file.path(getwd(), "EDSTATS_Country.csv")
download.file(url, f)
dtEd <- data.table(read.csv(f))
dt <- merge(dtGDP, dtEd, all = TRUE, by = c("CountryCode"))
sum(!is.na(unique(dt$rankingGDP)))
library(dpyr)
library("dpyr")
getwd
getwd()
library(data.table)
library(dplyr)
install.packages('data.table')
install.packages("data.table")
url <- "https://s3.amazonaws.com/coursera-uploads/peer-review/HkJsxW0yEeWEewoyD2Bc5Q/a2758386c7ebadcbe282be091b51e69d/result.txt"
fileX <- read.table(url)
head(fileX,5)
names(fileX)
url <- "https://s3.amazonaws.com/coursera-uploads/peer-review/HkJsxW0yEeWEewoyD2Bc5Q/d4a5fe28ab1acaf81294612b7d74ce18/newSet.txt"
fileX <- read.table(url)
head(fileX,5)
url <- "https://s3.amazonaws.com/coursera-uploads/peer-review/HkJsxW0yEeWEewoyD2Bc5Q/bb124f1ddf3add50aa6aee8938815692/tidyDataSet.txt"
fileX <- read.table(url)
head(fileX,5)
url <- "https://s3.amazonaws.com/coursera-uploads/peer-review/HkJsxW0yEeWEewoyD2Bc5Q/05cd9fe601a5328e4538aa6f0d13d317/wearable-data-file.txt"
dataX <- read.table(url)
head(dataX,3)
names(dataX)
nrows(dataX)
lenght(dataX)
factor(dataX$V1)
factor(dataX$V2)
install.packages("knitr")
library(knitr)
source('~/.active-rstudio-document', echo=TRUE)
getwd()
setwd("/Users/matej/Documents/Faks/Online Courses/Data Science/ReproducibleResearch/activityData/")
data <- read.table("activity.csv", sep = ",", na.strings = "NA")
summary(data)
str(data)
